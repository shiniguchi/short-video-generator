---
phase: 13-ugc-product-ad-pipeline
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - app/services/ugc_pipeline/asset_generator.py
  - app/services/ugc_pipeline/ugc_compositor.py
autonomous: true

must_haves:
  truths:
    - "Hero image is generated from product photo reference + UGC character prompt"
    - "A-Roll scenes are generated via Veo image-to-video from hero image with voice direction"
    - "B-Roll shots follow Imagen (static) then Veo image-to-video pipeline"
    - "UGC compositor concatenates A-Roll as base layer and overlays B-Roll at specified timestamps"
    - "Final composite is 9:16 MP4 with H.264/AAC encoding"
  artifacts:
    - path: "app/services/ugc_pipeline/asset_generator.py"
      provides: "generate_hero_image(), generate_aroll_assets(), generate_broll_assets() functions"
      contains: "def generate_hero_image"
    - path: "app/services/ugc_pipeline/ugc_compositor.py"
      provides: "compose_ugc_ad() function for A-Roll + B-Roll composition"
      contains: "def compose_ugc_ad"
  key_links:
    - from: "app/services/ugc_pipeline/asset_generator.py"
      to: "app/services/image_provider"
      via: "get_image_provider() factory"
      pattern: "from app.services.image_provider import get_image_provider"
    - from: "app/services/ugc_pipeline/asset_generator.py"
      to: "app/services/video_generator"
      via: "GoogleVeoProvider or MockVideoProvider for image-to-video"
      pattern: "from app.services.video_generator"
    - from: "app/services/ugc_pipeline/ugc_compositor.py"
      to: "moviepy"
      via: "VideoFileClip, CompositeVideoClip, concatenate_videoclips"
      pattern: "from moviepy import"
---

<objective>
Create asset generation and composition services for the UGC ad pipeline.

Purpose: Implements the visual production backend -- generating hero images, A-Roll video scenes, B-Roll product shots, and compositing them into a final 9:16 MP4. These services use existing provider abstractions (ImageProvider, VideoProvider) and MoviePy v2 for composition.

Output: An asset_generator module that orchestrates Imagen + Veo calls for all visual assets, and a ugc_compositor module that assembles A-Roll base + B-Roll overlays into the final video.
</objective>

<execution_context>
@/Users/naokitsk/.claude/get-shit-done/workflows/execute-plan.md
@/Users/naokitsk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-ugc-product-ad-pipeline/13-RESEARCH.md
@app/services/image_provider/base.py
@app/services/image_provider/__init__.py
@app/services/video_generator/google_veo.py
@app/services/video_generator/generator.py
@app/services/video_compositor/compositor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create asset_generator.py for hero image, A-Roll, and B-Roll generation</name>
  <files>app/services/ugc_pipeline/asset_generator.py</files>
  <action>
Create `app/services/ugc_pipeline/asset_generator.py` with three main functions. Use `from typing import List, Optional, Dict, Any` (Python 3.9 compat).

**generate_hero_image(product_image_path, ugc_style, emotional_tone, visual_keywords):**
1. Calls `get_image_provider()` from `app.services.image_provider`
2. Builds a prompt combining UGC character description + product integration:
   - "A photo of a {ugc_style} UGC creator holding and showcasing the product..."
   - Includes visual_keywords for style guidance
   - Emphasizes "Raw UGC feel, not overly polished, authentic social media content"
3. Calls `image_provider.generate_image(prompt=..., width=720, height=1280, num_images=1, reference_images=[product_image_path])`
4. Returns the path to the generated hero image (first item from list)
5. Logs the generation

**generate_aroll_assets(aroll_scenes, hero_image_path):**
1. Takes a `List[dict]` of A-Roll scene dicts (from AdBreakdown.aroll_scenes, each dict has visual_prompt, duration_seconds, voice_direction, script_text)
2. For each scene, generates a video clip using Veo's image-to-video mode:
   - Get video provider: Use `GoogleVeoProvider` directly (not the VideoGeneratorService, since we need image-to-video). Import from `app.services.video_generator.google_veo`. Get google_api_key and output_dir from settings.
   - Call `veo.generate_clip_from_image(prompt=scene["visual_prompt"] + " " + scene["voice_direction"], image_path=hero_image_path, duration_seconds=scene["duration_seconds"], width=720, height=1280)`
   - Collect all clip paths in order
3. Returns `List[str]` of A-Roll clip paths in scene order
4. Logs each scene generation with frame_number and duration

**generate_broll_assets(broll_shots, product_image_path):**
1. Takes a `List[dict]` of B-Roll shot dicts (from AdBreakdown.broll_shots, each dict has image_prompt, animation_prompt, duration_seconds)
2. For each shot, two-step pipeline:
   - Step 1: `get_image_provider().generate_image(prompt=shot["image_prompt"], width=720, height=1280, num_images=1, reference_images=[product_image_path])`
   - Step 2: `veo.generate_clip_from_image(prompt=shot["animation_prompt"], image_path=product_shot_path, duration_seconds=shot["duration_seconds"], width=720, height=1280)`
3. Returns `List[str]` of B-Roll clip paths in shot order
4. Logs each shot generation with shot_number

**IMPORTANT implementation notes:**
- When constructing GoogleVeoProvider, check `settings.use_mock_data` — if True or if `settings.google_api_key` is empty, use MockVideoProvider instead (same fallback pattern as existing video_generator/generator.py). Create a helper function `_get_veo_or_mock()` that returns a provider instance.
- All functions are synchronous (called from sync Celery context)
- Ensure proper resource cleanup — no open file handles left
- Use `import logging; logger = logging.getLogger(__name__)` for logging
  </action>
  <verify>Run `python -c "from app.services.ugc_pipeline.asset_generator import generate_hero_image, generate_aroll_assets, generate_broll_assets; print('Asset generator importable')"` from project root (with venv activated).</verify>
  <done>asset_generator.py has generate_hero_image(), generate_aroll_assets(), generate_broll_assets() functions. All use existing provider abstractions. Veo/mock fallback works based on settings. Functions are synchronous for Celery compatibility.</done>
</task>

<task type="auto">
  <name>Task 2: Create ugc_compositor.py for A-Roll + B-Roll composition</name>
  <files>app/services/ugc_pipeline/ugc_compositor.py</files>
  <action>
Create `app/services/ugc_pipeline/ugc_compositor.py` with the main composition function. Use `from typing import List, Dict, Any, Optional` (Python 3.9 compat).

**compose_ugc_ad(aroll_paths, broll_metadata, output_path):**
1. `aroll_paths`: List[str] — ordered paths to A-Roll video clips
2. `broll_metadata`: List[dict] — each dict has "path" (str) and "overlay_start" (float)
3. `output_path`: str — where to write the final MP4

**Implementation steps:**
1. Import MoviePy v2 correctly: `from moviepy import VideoFileClip, CompositeVideoClip, concatenate_videoclips`
2. Load all A-Roll clips: `aroll_clips = [VideoFileClip(path) for path in aroll_paths]`
3. Concatenate A-Roll into base layer: `base_video = concatenate_videoclips(aroll_clips, method="compose")`
4. Calculate cumulative A-Roll timings for B-Roll overlay validation:
   - `aroll_durations = [clip.duration for clip in aroll_clips]`
   - `total_aroll_duration = sum(aroll_durations)`
5. Load B-Roll clips and position at overlay timestamps:
   - For each broll in broll_metadata:
     - `clip = VideoFileClip(broll["path"])`
     - `overlay = clip.with_start(broll["overlay_start"]).with_position(("center", "center")).resized(0.8)` (80% scale for picture-in-picture)
     - Validate: if `broll["overlay_start"] + clip.duration > total_aroll_duration`, clamp or warn
     - Append to overlays list
6. Composite: `final_video = CompositeVideoClip([base_video] + broll_overlays, size=(720, 1280))`
7. Note: A-Roll from Veo has built-in voice/audio. The base_video audio from concatenation should be preserved. Do NOT strip audio. If B-Roll clips have audio, mute them: `overlay = clip.without_audio().with_start(...)...`
8. Write final: `final_video.write_videofile(output_path, codec="libx264", audio_codec="aac", fps=30, preset="medium", bitrate="5M", audio_bitrate="128k")`
9. Cleanup: Close all clips explicitly:
   ```python
   for clip in aroll_clips:
       clip.close()
   for clip in broll_overlays:
       clip.close()
   base_video.close()
   final_video.close()
   ```
10. Return `output_path`

**Edge cases to handle:**
- Empty broll_metadata: Just concatenate A-Roll and write (no overlays needed)
- Single A-Roll scene: No concatenation needed, use clip directly as base
- Log total duration and clip count

**MoviePy v2 immutable API reminders (from Phase 4 decisions):**
- Use `with_start()`, `with_position()` — NOT `set_start()`, `set_position()`
- Use `clip.resized(0.8)` — NOT `clip.resize(0.8)` (immutable API)
- Use `clip.without_audio()` to strip audio from B-Roll overlays
  </action>
  <verify>Run `python -c "from app.services.ugc_pipeline.ugc_compositor import compose_ugc_ad; print('UGC compositor importable')"` from project root (with venv activated).</verify>
  <done>ugc_compositor.py has compose_ugc_ad() function that concatenates A-Roll as base layer, overlays B-Roll at specified timestamps with 80% scale, writes 9:16 MP4 with H.264/AAC encoding. Handles empty B-Roll and single A-Roll edge cases. Proper MoviePy v2 immutable API usage. Explicit resource cleanup.</done>
</task>

</tasks>

<verification>
1. asset_generator.py imports without error
2. ugc_compositor.py imports without error
3. generate_hero_image uses ImageProvider with reference_images parameter
4. generate_aroll_assets uses Veo image-to-video (or mock fallback)
5. generate_broll_assets uses Imagen then Veo image-to-video pipeline
6. compose_ugc_ad uses MoviePy v2 immutable API correctly
7. B-Roll audio is stripped (without_audio()) to prevent audio conflicts
8. All clips are explicitly closed after composition
</verification>

<success_criteria>
- generate_hero_image() generates 720x1280 image using product photo as reference
- generate_aroll_assets() generates video clips from hero image for each scene
- generate_broll_assets() generates Imagen image then Veo animation for each shot
- compose_ugc_ad() creates final 9:16 MP4 from A-Roll base + B-Roll overlays
- All functions use mock providers when USE_MOCK_DATA=true
- MoviePy v2 immutable API used throughout (with_* methods, resized())
</success_criteria>

<output>
After completion, create `.planning/phases/13-ugc-product-ad-pipeline/13-02-SUMMARY.md`
</output>
